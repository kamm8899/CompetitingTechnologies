{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2336946775b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: /Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_4\n",
      "Processing folder: /Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_5\n",
      "Processing folder: /Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_8\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\n",
    "'/Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_4',\n",
    "'/Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_5',\n",
    "'/Users/jessicakammann/Desktop/ResearchAlzheimers/ADNI_8'\n",
    "]\n",
    "\n",
    "\n",
    "# Function to process .nii files\n",
    "def process_nii_files(folder_paths):\n",
    "    for folder_path in folder_paths:\n",
    "        print(f\"Processing folder: {folder_path}\")\n",
    "        \n",
    "                # Iterate through all .nii files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.nii') or file_name.endswith('.nii.gz'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Load the .nii file\n",
    "                img = nib.load(file_path)\n",
    "                img_data = img.get_fdata()\n",
    "                \n",
    "                # Print basic information about the file\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Shape: {img_data.shape}\")\n",
    "                \n",
    "                # Example: Visualize the middle slice of the 3D image\n",
    "                if len(img_data.shape) == 3:  # Ensure it's a 3D image\n",
    "                    slice_index = img_data.shape[2] // 2  # Middle slice\n",
    "                    plt.imshow(img_data[:, :, slice_index], cmap='gray')\n",
    "                    plt.title(f\"Slice {slice_index} of {file_name}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "# Call the function\n",
    "process_nii_files(folder_paths)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/hr/3dhbmnc50n7csq4c8dgqc60r0000gn/T/ipykernel_29564/2986640943.py\", line 1, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/jessicakammann/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files loaded so far...\n",
      "20 files loaded so far...\n",
      "30 files loaded so far...\n",
      "40 files loaded so far...\n",
      "50 files loaded so far...\n",
      "60 files loaded so far...\n",
      "70 files loaded so far...\n",
      "80 files loaded so far...\n",
      "90 files loaded so far...\n",
      "100 files loaded so far...\n",
      "110 files loaded so far...\n",
      "120 files loaded so far...\n",
      "130 files loaded so far...\n",
      "140 files loaded so far...\n",
      "150 files loaded so far...\n",
      "160 files loaded so far...\n",
      "170 files loaded so far...\n",
      "180 files loaded so far...\n",
      "190 files loaded so far...\n",
      "200 files loaded so far...\n",
      "210 files loaded so far...\n",
      "220 files loaded so far...\n",
      "230 files loaded so far...\n",
      "240 files loaded so far...\n",
      "250 files loaded so far...\n",
      "260 files loaded so far...\n",
      "270 files loaded so far...\n",
      "280 files loaded so far...\n",
      "290 files loaded so far...\n",
      "300 files loaded so far...\n",
      "310 files loaded so far...\n",
      "320 files loaded so far...\n",
      "330 files loaded so far...\n",
      "340 files loaded so far...\n",
      "350 files loaded so far...\n",
      "360 files loaded so far...\n",
      "370 files loaded so far...\n",
      "380 files loaded so far...\n",
      "390 files loaded so far...\n",
      "400 files loaded so far...\n",
      "410 files loaded so far...\n",
      "420 files loaded so far...\n",
      "430 files loaded so far...\n",
      "440 files loaded so far...\n",
      "450 files loaded so far...\n",
      "460 files loaded so far...\n",
      "470 files loaded so far...\n",
      "480 files loaded so far...\n",
      "490 files loaded so far...\n",
      "500 files loaded so far...\n",
      "510 files loaded so far...\n",
      "520 files loaded so far...\n",
      "530 files loaded so far...\n",
      "540 files loaded so far...\n",
      "550 files loaded so far...\n",
      "560 files loaded so far...\n",
      "570 files loaded so far...\n",
      "580 files loaded so far...\n",
      "590 files loaded so far...\n",
      "600 files loaded so far...\n",
      "610 files loaded so far...\n",
      "620 files loaded so far...\n",
      "630 files loaded so far...\n",
      "640 files loaded so far...\n",
      "650 files loaded so far...\n",
      "660 files loaded so far...\n",
      "670 files loaded so far...\n",
      "680 files loaded so far...\n",
      "690 files loaded so far...\n",
      "700 files loaded so far...\n",
      "710 files loaded so far...\n",
      "720 files loaded so far...\n",
      "730 files loaded so far...\n",
      "740 files loaded so far...\n",
      "750 files loaded so far...\n",
      "760 files loaded so far...\n",
      "770 files loaded so far...\n",
      "780 files loaded so far...\n",
      "790 files loaded so far...\n",
      "800 files loaded so far...\n",
      "810 files loaded so far...\n",
      "820 files loaded so far...\n",
      "830 files loaded so far...\n",
      "840 files loaded so far...\n",
      "850 files loaded so far...\n",
      "860 files loaded so far...\n",
      "870 files loaded so far...\n",
      "880 files loaded so far...\n",
      "890 files loaded so far...\n",
      "900 files loaded so far...\n",
      "910 files loaded so far...\n",
      "920 files loaded so far...\n",
      "930 files loaded so far...\n",
      "940 files loaded so far...\n",
      "950 files loaded so far...\n",
      "960 files loaded so far...\n",
      "970 files loaded so far...\n",
      "980 files loaded so far...\n",
      "990 files loaded so far...\n",
      "1000 files loaded so far...\n",
      "1010 files loaded so far...\n",
      "1020 files loaded so far...\n",
      "1030 files loaded so far...\n",
      "1040 files loaded so far...\n",
      "1050 files loaded so far...\n",
      "1060 files loaded so far...\n",
      "1070 files loaded so far...\n",
      "1080 files loaded so far...\n",
      "1090 files loaded so far...\n",
      "1100 files loaded so far...\n",
      "1110 files loaded so far...\n",
      "1120 files loaded so far...\n",
      "1130 files loaded so far...\n",
      "1140 files loaded so far...\n",
      "1150 files loaded so far...\n",
      "1160 files loaded so far...\n",
      "1170 files loaded so far...\n",
      "1180 files loaded so far...\n",
      "1190 files loaded so far...\n",
      "1200 files loaded so far...\n",
      "1210 files loaded so far...\n",
      "1220 files loaded so far...\n",
      "1230 files loaded so far...\n",
      "1240 files loaded so far...\n",
      "1250 files loaded so far...\n",
      "1260 files loaded so far...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not all tensors have the same shape. Found shapes: {torch.Size([256, 256, 170]), torch.Size([256, 256, 160]), torch.Size([256, 256, 166]), torch.Size([256, 256, 150]), torch.Size([256, 256, 124]), torch.Size([256, 256, 161]), torch.Size([256, 256, 162]), torch.Size([192, 192, 160]), torch.Size([256, 256, 184]), torch.Size([256, 256, 180])}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hr/3dhbmnc50n7csq4c8dgqc60r0000gn/T/ipykernel_29564/2986640943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#folders_to_search = ['/path/to/folder1', '/path/to/folder2']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nii_files_and_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/hr/3dhbmnc50n7csq4c8dgqc60r0000gn/T/ipykernel_29564/2986640943.py\u001b[0m in \u001b[0;36mfind_nii_files_and_stack\u001b[0;34m(folders, verbose)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnii_tensors\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Not all tensors have the same shape. Found shapes: {shapes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mstacked_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not all tensors have the same shape. Found shapes: {torch.Size([256, 256, 170]), torch.Size([256, 256, 160]), torch.Size([256, 256, 166]), torch.Size([256, 256, 150]), torch.Size([256, 256, 124]), torch.Size([256, 256, 161]), torch.Size([256, 256, 162]), torch.Size([192, 192, 160]), torch.Size([256, 256, 184]), torch.Size([256, 256, 180])}"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "def find_nii_files_and_stack(folders, verbose=True):\n",
    "    \"\"\"\n",
    "    Recursively search folders and subfolders for .nii or .nii.gz files.\n",
    "    Load them into PyTorch tensors and return a single stacked tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - folders (list of str): List of folder paths to search.\n",
    "    - verbose (bool): Whether to print progress updates.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor stacked along a new dimension (e.g., first dim is number of files).\n",
    "    \"\"\"\n",
    "    nii_tensors = []\n",
    "    count = 0\n",
    "\n",
    "    for folder in folders:\n",
    "        for root, _, files in os.walk(folder):\n",
    "            # Define a target shape (e.g., (128, 128, 128))\n",
    "            target_shape = (128, 128, 128)\n",
    "            for file in files:\n",
    "                if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    try:\n",
    "                        nii = nib.load(filepath)\n",
    "                        data = torch.tensor(nii.get_fdata(), dtype=torch.float32)\n",
    "                        nii_tensors.append(data)\n",
    "                        count += 1\n",
    "                        if verbose and count % 10 == 0:\n",
    "                            print(f\"{count} files loaded so far...\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load {filepath}: {e}\")\n",
    "   \n",
    "    if not nii_tensors:\n",
    "        raise ValueError(\"No .nii or .nii.gz files found.\")\n",
    "\n",
    "    # Make sure all tensors are the same shape before stacking\n",
    "    shapes = {tensor.shape for tensor in nii_tensors}\n",
    "    if len(shapes) > 1:\n",
    "        raise ValueError(f\"Not all tensors have the same shape. Found shapes: {shapes}\")\n",
    "\n",
    "    stacked_tensor = torch.stack(nii_tensors)\n",
    "    if verbose:\n",
    "        print(f\"Done. {count} files loaded into a tensor of shape {stacked_tensor.shape}.\")\n",
    "    return stacked_tensor\n",
    "\n",
    "\n",
    "#folders_to_search = ['/path/to/folder1', '/path/to/folder2']\n",
    "tensor = find_nii_files_and_stack(folder_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
